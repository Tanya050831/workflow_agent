{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7a97db",
   "metadata": {},
   "source": [
    "Tensor:å¼ é‡\n",
    "\n",
    "Numpyé‡Œè¿™ä¸ªå«array(æ•°ç»„);pytorché‡Œå«tensor(å¼ é‡)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60684c5c",
   "metadata": {},
   "source": [
    "å®ƒä»¬é•¿å¾—ä¸€æ¨¡ä¸€æ ·ï¼Œç”¨æ³•ä¹Ÿå‡ ä¹ä¸€æ ·ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯ï¼š\n",
    "\n",
    "\n",
    "NumPy Arrayï¼šåªèƒ½åœ¨ CPU ä¸Šè·‘ï¼ˆè€å®äººï¼Œç®—å¾—æ…¢ï¼‰ã€‚\n",
    "\n",
    "\n",
    "PyTorch Tensorï¼šå¯ä»¥åœ¨ GPU ä¸Šè·‘ï¼ˆç©¿äº†é’¢é“ä¾ æˆ˜è¡£ï¼Œç®—å¾—é£å¿«ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6172194f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch ç‰ˆæœ¬: 2.7.1\n"
     ]
    }
   ],
   "source": [
    "#ç¯å¢ƒè‡ªæ£€\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"PyTorch ç‰ˆæœ¬:\", torch.__version__)\n",
    "# å¦‚æœæ²¡æŠ¥é”™ï¼Œæ‰“å°å‡ºäº†ç‰ˆæœ¬å·ï¼ˆæ¯”å¦‚ 2.x.xï¼‰ï¼Œè¯´æ˜å®‰è£…æˆåŠŸï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801e5f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "éšæœºæ•°å¼ é‡:\n",
      " tensor([[0.8056, 0.6704, 0.8261],\n",
      "        [0.7292, 0.3310, 0.9392]])\n",
      "é›¶å¼ é‡:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "å…¨ä¸€å¼ é‡:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "å¼ é‡çš„å½¢çŠ¶: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "data = [1,2,3]\n",
    "#åŸæ¥çš„numpy: arr = np.array(data)\n",
    "tensor = torch.tensor(data)\n",
    "print(tensor)\n",
    "\n",
    "#ç”Ÿæˆéšæœºæ•°\n",
    "random_tensor = torch.rand(2,3)  # 2è¡Œ3åˆ—çš„éšæœºæ•°å¼ é‡\n",
    "zero_tensor = torch.zeros(2,3)  # 2è¡Œ3åˆ—çš„é›¶å¼ é‡\n",
    "one_tensor = torch.ones(2,3)    # 2è¡Œ3åˆ—çš„å…¨ä¸€å¼ é‡\n",
    "print(\"éšæœºæ•°å¼ é‡:\\n\", random_tensor)\n",
    "print(\"é›¶å¼ é‡:\\n\", zero_tensor)\n",
    "print(\"å…¨ä¸€å¼ é‡:\\n\", one_tensor)\n",
    "print(\"å¼ é‡çš„å½¢çŠ¶:\", random_tensor.shape)  # è¾“å‡ºå¼ é‡çš„å½¢çŠ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e9654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å½“å‰è®¾å¤‡: cpu\n"
     ]
    }
   ],
   "source": [
    "#è®¾å¤‡æ£€æµ‹: cpuè¿˜æ˜¯gpu\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(\"å½“å‰è®¾å¤‡:\", x.device) # è¾“å‡ºåº”è¯¥æ˜¯ cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6036cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¬è¿åè®¾å¤‡: mps:0\n",
      "åŸæ¥çš„ x è¿˜åœ¨å—ï¼Ÿ cpu\n"
     ]
    }
   ],
   "source": [
    "# 2. ã€é­”æ³•æ­¥éª¤ã€‘æ¬è¿åˆ° GPU (Mac MèŠ¯ç‰‡)\n",
    "# å¦‚æœä½ æ˜¯ Windows/Linux Nå¡ç”¨æˆ·ï¼Œè¿™é‡Œå†™ 'cuda'\n",
    "# å¦‚æœä½ æ˜¯ Mac MèŠ¯ç‰‡ç”¨æˆ·ï¼Œè¿™é‡Œå†™ 'mps'\n",
    "if torch.backends.mps.is_available():\n",
    "    x_gpu = x.to('mps')\n",
    "    print(\"æ¬è¿åè®¾å¤‡:\", x_gpu.device) # è¾“å‡ºåº”è¯¥æ˜¯ mps:0\n",
    "    print(\"åŸæ¥çš„ x è¿˜åœ¨å—ï¼Ÿ\", x.device) # è¿˜åœ¨ CPUï¼Œ.to() æ˜¯è¿”å›ä¸€ä¸ªæ–°å‰¯æœ¬\n",
    "else:\n",
    "    print(\"ä½ çš„ç”µè„‘ä¸æ”¯æŒ MPS åŠ é€Ÿï¼Œåªèƒ½ç”¨ CPU è·‘ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11391f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy å˜èº«: tensor([5, 6, 7])\n",
      "å˜å›åŸå½¢: [5 6 7]\n"
     ]
    }
   ],
   "source": [
    "#***numpy å’Œ tensor äº’è½¬***\n",
    "# 1. NumPy -> Tensor\n",
    "np_array = np.array([5, 6, 7])\n",
    "tensor_from_np = torch.from_numpy(np_array)\n",
    "print(\"NumPy å˜èº«:\", tensor_from_np)\n",
    "\n",
    "# 2. Tensor -> NumPy\n",
    "back_to_np = tensor_from_np.numpy()\n",
    "print(\"å˜å›åŸå½¢:\", back_to_np)\n",
    "\n",
    "# ğŸš¨ è­¦å‘Šï¼šå¦‚æœ Tensor åœ¨ GPU (mps/cuda) ä¸Šï¼Œå¿…é¡»å…ˆæ¬å› CPU æ‰èƒ½è½¬ NumPy\n",
    "# x_gpu.numpy() # è¿™è¡Œä¼šæŠ¥é”™ï¼\n",
    "# æ­£ç¡®å†™æ³•ï¼š\n",
    "# x_gpu.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edf740a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5af8f9af",
   "metadata": {},
   "source": [
    "day1é€šå…³: å¼ é‡åˆä½“éªŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01f94848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2152, 1.4365],\n",
      "        [1.6780, 1.8078],\n",
      "        [2.2421, 2.4994],\n",
      "        [1.4841, 1.5690],\n",
      "        [1.4779, 1.7536]])\n",
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "tensor = torch.rand(5, 3)\n",
    "tensor2 = torch.rand(3,2)\n",
    "Y = torch.mm(tensor, tensor2)+ torch.ones(2, )\n",
    "#Y2 = torch.mm(tensor, tensor2)+ torch.ones(2,2 )\n",
    "\n",
    "\n",
    "print(Y)\n",
    "\n",
    "print(Y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f09cb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4236, 1.6794],\n",
      "        [1.3888, 1.5809],\n",
      "        [0.5656, 0.3919],\n",
      "        [0.1731, 0.1416],\n",
      "        [0.2710, 0.1711]])\n"
     ]
    }
   ],
   "source": [
    "#åªæƒ³ç»™å‰ä¸¤è¡ŒåŠ bias\n",
    "Y3 = torch.mm(tensor, tensor2)\n",
    "Y3[:2, :] = Y3[:2, :] + torch.ones(2, ) #è¡Œå– 0 å’Œ 1ï¼Œåˆ—å–å…¨éƒ¨\n",
    "print(Y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f731ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d053462f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available? False\n",
      "Is MPS available? True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. æ£€æŸ¥æ˜¯ä¸æ˜¯ NVIDIA æ˜¾å¡ (Mac ä¸Šè‚¯å®šæ˜¯ False)\n",
    "print(\"Is CUDA available?\", torch.cuda.is_available())\n",
    "\n",
    "# 2. æ£€æŸ¥æ˜¯ä¸æ˜¯ Mac MèŠ¯ç‰‡åŠ é€Ÿ (MPS)\n",
    "# è¿™æ‰æ˜¯ä½ åº”è¯¥å…³æ³¨çš„ï¼å¦‚æœæ˜¯ Trueï¼Œè¯´æ˜ä½ çš„ Mac æ˜¾å¡èµ·é£äº†ï¼\n",
    "print(\"Is MPS available?\", torch.backends.mps.is_available())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
