# AI Agent for Complex Physics Problem Solving

# å¤æ‚ç‰©ç†é—®é¢˜æ±‚è§£çš„AIæ™ºèƒ½ä½“

## Abstract | æ‘˜è¦

Scientific reasoning represents one of the most challenging aspects of education, requiring students to integrate multiple forms of information and apply complex problem-solving strategies. This project develops an innovative agent-based framework to solve complex illustrated physics problems, leveraging platforms like Coze and Hiagent to create a specialized agent that mimics human problem-solving by interpreting multimodal information. This approach demonstrates a viable pathway for creating sophisticated AI tutors for advanced scientific education.

ç§‘å­¦æ¨ç†æ˜¯æ•™è‚²ä¸­æœ€å…·æŒ‘æˆ˜æ€§çš„æ–¹é¢ä¹‹ä¸€ï¼Œè¦æ±‚å­¦ç”Ÿæ•´åˆå¤šç§å½¢å¼çš„ä¿¡æ¯å¹¶åº”ç”¨å¤æ‚çš„é—®é¢˜è§£å†³ç­–ç•¥ã€‚æœ¬é¡¹ç›®å¼€å‘äº†ä¸€ä¸ªåˆ›æ–°çš„åŸºäºæ™ºèƒ½ä½“çš„æ¡†æ¶æ¥è§£å†³å¤æ‚çš„å›¾ç¤ºç‰©ç†é—®é¢˜ï¼Œåˆ©ç”¨Cozeå’ŒHiagentç­‰å¹³å°åˆ›å»ºä¸€ä¸ªä¸“é—¨çš„æ™ºèƒ½ä½“ï¼Œé€šè¿‡è§£é‡Šå¤šæ¨¡æ€ä¿¡æ¯æ¥æ¨¡æ‹Ÿäººç±»çš„é—®é¢˜è§£å†³è¿‡ç¨‹ã€‚è¿™ç§æ–¹æ³•ä¸ºåˆ›å»ºå…ˆè¿›çš„ç§‘å­¦æ•™è‚²AIå¯¼å¸ˆæä¾›äº†ä¸€æ¡å¯è¡Œçš„é€”å¾„ã€‚

## Introduction | ç®€ä»‹

### Dataset | æ•°æ®é›†

We developed an agent to solve a diverse dataset of **2,000 physics problems**. This dataset includes:

æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªæ™ºèƒ½ä½“æ¥è§£å†³åŒ…å«**2000ä¸ªç‰©ç†é—®é¢˜**çš„å¤šæ ·åŒ–æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…æ‹¬ï¼š

- **Languages**: Questions in both Chinese and English
- **Languages | è¯­è¨€**: ä¸­è‹±æ–‡é—®é¢˜
- **Categories**: Eight distinct categories (CM, OPT, ACG, EM, QMIT, AMONP, TSM)
- **Categories | ç±»åˆ«**: å…«ä¸ªä¸åŒç±»åˆ«ï¼ˆCM, OPT, ACG, EM, QMIT, AMONP, TSMï¼‰
- **Difficulty Levels**: Seven distinct difficulty levels, ranging from middle school to doctoral studies
- **Difficulty Levels | éš¾åº¦çº§åˆ«**: ä¸ƒä¸ªä¸åŒçš„éš¾åº¦çº§åˆ«ï¼Œä»ä¸­å­¦åˆ°åšå£«ç ”ç©¶

### Methodology | æ–¹æ³•è®º

We adopted a controlled experimental approach to enhance the workflow's performance. We isolated and evaluated several key components as single variables:

æˆ‘ä»¬é‡‡ç”¨å—æ§å®éªŒæ–¹æ³•æ¥æå‡å·¥ä½œæµçš„æ€§èƒ½ã€‚æˆ‘ä»¬å°†å‡ ä¸ªå…³é”®ç»„ä»¶ä½œä¸ºå•ä¸€å˜é‡è¿›è¡Œéš”ç¦»å’Œè¯„ä¼°ï¼š

1. **Model Architecture | æ¨¡å‹æ¶æ„**
   - **Unified Multimodal**: Using a single multimodal model (Model_Only_MultiModal) for both diagram interpretation and reasoning
   - **ç»Ÿä¸€å¤šæ¨¡æ€**: ä½¿ç”¨å•ä¸€å¤šæ¨¡æ€æ¨¡å‹ï¼ˆModel_Only_MultiModalï¼‰è¿›è¡Œå›¾è¡¨è§£é‡Šå’Œæ¨ç†
   - **Core Engine Swap**: Replacing the baseline reasoning model with a more powerful one (Model_Deepseek-r1)
   - **æ ¸å¿ƒå¼•æ“æ›¿æ¢**: ç”¨æ›´å¼ºå¤§çš„æ¨¡å‹ï¼ˆModel_Deepseek-r1ï¼‰æ›¿æ¢åŸºçº¿æ¨ç†æ¨¡å‹

2. **Language | è¯­è¨€**
   - Applying a Chinese-to-English translation pre-processing step to standardize the input
   - åº”ç”¨ä¸­è‹±æ–‡ç¿»è¯‘é¢„å¤„ç†æ­¥éª¤ä»¥æ ‡å‡†åŒ–è¾“å…¥

3. **RAG (Retrieval-Augmented Generation) | æ£€ç´¢å¢å¼ºç”Ÿæˆ**
   - **Textbook RAG**: Using only foundational textbook knowledge
   - **æ•™ç§‘ä¹¦RAG**: ä»…ä½¿ç”¨åŸºç¡€æ•™ç§‘ä¹¦çŸ¥è¯†
   - **Enhanced RAG**: Augmenting textbooks with a database of 1,800 solved problems with detailed solutions
   - **å¢å¼ºRAG**: ç”¨åŒ…å«1800ä¸ªå·²è§£å†³é—®é¢˜åŠè¯¦ç»†è§£ç­”çš„æ•°æ®åº“å¢å¼ºæ•™ç§‘ä¹¦çŸ¥è¯†

4. **Feedback | åé¦ˆ**
   - Implementing a self-correcting feedback loop for the agent
   - ä¸ºæ™ºèƒ½ä½“å®ç°è‡ªæˆ‘çº æ­£åé¦ˆå¾ªç¯

## Problem-Solving Methodology | é—®é¢˜è§£å†³æ–¹æ³•è®º

### Architecture | æ¶æ„

![Problem-Solving Methodology](images/methodology.png)

*Figure 1: Problem-Solving Methodology Architecture*

*å›¾1: é—®é¢˜è§£å†³æ–¹æ³•è®ºæ¶æ„*

Our system consists of:

æˆ‘ä»¬çš„ç³»ç»ŸåŒ…æ‹¬ï¼š

- **Core Agent**: Central reasoning component (represented by a brain within a chip)
- **æ ¸å¿ƒæ™ºèƒ½ä½“**: ä¸­å¤®æ¨ç†ç»„ä»¶ï¼ˆä»¥èŠ¯ç‰‡ä¸­çš„å¤§è„‘å›¾æ ‡è¡¨ç¤ºï¼‰
- **Input Stage**: Processes multimodal input (text and diagrams)
- **è¾“å…¥é˜¶æ®µ**: å¤„ç†å¤šæ¨¡æ€è¾“å…¥ï¼ˆæ–‡æœ¬å’Œå›¾è¡¨ï¼‰
- **Output Stage**: Generates solutions
- **è¾“å‡ºé˜¶æ®µ**: ç”Ÿæˆè§£å†³æ–¹æ¡ˆ
- **Supporting Components**:
  - **æ”¯æŒç»„ä»¶**:
  - Retrieval-Augmented Generation (RAG)
  - æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰
  - Diagram Interpretation
  - å›¾è¡¨è§£é‡Š
  - Core Model
  - æ ¸å¿ƒæ¨¡å‹

### Experimental Design | å®éªŒè®¾è®¡

We conducted a rigorous ablation study, isolating one variable at a time to measure the impact of each component. Each configuration was evaluated based on its accuracy on our 200-problem development set.

æˆ‘ä»¬è¿›è¡Œäº†ä¸¥æ ¼çš„æ¶ˆèç ”ç©¶ï¼Œæ¯æ¬¡éš”ç¦»ä¸€ä¸ªå˜é‡ä»¥æµ‹é‡æ¯ä¸ªç»„ä»¶çš„å½±å“ã€‚æ¯ä¸ªé…ç½®éƒ½åŸºäºæˆ‘ä»¬åœ¨200ä¸ªé—®é¢˜çš„å¼€å‘é›†ä¸Šçš„å‡†ç¡®ç‡è¿›è¡Œè¯„ä¼°ã€‚

## Results | ç»“æœ

### Performance Comparison | æ€§èƒ½å¯¹æ¯”

![Results Table](images/results_table.png)

*Figure 2: Performance Comparison Results*

*å›¾2: æ€§èƒ½å¯¹æ¯”ç»“æœ*

| Method / Component | Percent | æ–¹æ³•/ç»„ä»¶ | ç™¾åˆ†æ¯” |
|-------------------|---------|----------|--------|
| Baseline | 0.350 | åŸºçº¿ | 0.350 |
| Model: Model_Only_MultiModal | 0.290 | æ¨¡å‹: Model_Only_MultiModal | 0.290 |
| Model: Model_Deepseek-r1 | 0.400 | æ¨¡å‹: Model_Deepseek-r1 | 0.400 |
| Language: Language_Chi_translate_to_Eng | **0.395** | è¯­è¨€: ä¸­æ–‡ç¿»è¯‘ä¸ºè‹±æ–‡ | **0.395** |
| RAG: RAG_without1800 | 0.375 | RAG: æ— 1800é¢˜RAG | 0.375 |
| RAG: RAG_with1800 | 0.380 | RAG: æœ‰1800é¢˜RAG | 0.380 |
| Feedback: Feedback_Use | 0.350 | åé¦ˆ: ä½¿ç”¨åé¦ˆ | 0.350 |
| **Integrated Method** | **0.450** | **é›†æˆæ–¹æ³•** | **0.450** |

### Key Findings | å…³é”®å‘ç°

1. **Overall Accuracy Boost**: The Integrated Method boosts overall accuracy from **35.0%** (70/200) to **45.0%** (90/200)
   - **æ•´ä½“å‡†ç¡®ç‡æå‡**: é›†æˆæ–¹æ³•å°†æ•´ä½“å‡†ç¡®ç‡ä»**35.0%**ï¼ˆ70/200ï¼‰æå‡åˆ°**45.0%**ï¼ˆ90/200ï¼‰

2. **Primary Gain**: The integrated method successfully corrected **35 problems** that the baseline failed
   - **ä¸»è¦æ”¶ç›Š**: é›†æˆæ–¹æ³•æˆåŠŸçº æ­£äº†åŸºçº¿å¤±è´¥çš„**35ä¸ªé—®é¢˜**

3. **Performance Trade-off**: The new method introduced errors on **15 problems** that the baseline had previously answered correctly
   - **æ€§èƒ½æƒè¡¡**: æ–°æ–¹æ³•åœ¨åŸºçº¿å…ˆå‰æ­£ç¡®å›ç­”çš„**15ä¸ªé—®é¢˜**ä¸Šå¼•å…¥äº†é”™è¯¯

4. **Net Improvement**: The net gain is **20 correct answers** (35 improvements - 15 regressions)
   - **å‡€æ”¹è¿›**: å‡€æ”¶ç›Šä¸º**20ä¸ªæ­£ç¡®ç­”æ¡ˆ**ï¼ˆ35ä¸ªæ”¹è¿› - 15ä¸ªå›å½’ï¼‰

5. **Future Challenges**: **95 problems** remained incorrect for both methods, indicating difficult cases for future research
   - **æœªæ¥æŒ‘æˆ˜**: **95ä¸ªé—®é¢˜**åœ¨ä¸¤ç§æ–¹æ³•ä¸­éƒ½ä¿æŒé”™è¯¯ï¼Œè¡¨æ˜è¿™äº›æ˜¯æœªæ¥ç ”ç©¶çš„å›°éš¾æ¡ˆä¾‹

![Analysis Sankey Diagram](images/analysis_sankey.png)

*Figure 3: Performance Analysis - Baseline vs Integrated Method*

*å›¾3: æ€§èƒ½åˆ†æ - åŸºçº¿æ–¹æ³• vs é›†æˆæ–¹æ³•*

### Component Analysis | ç»„ä»¶åˆ†æ

- **Component Synergy is Crucial**: The integrated method, combining effective components, achieved 45.0% accuracy, outperforming the 35.0% baseline
  - **ç»„ä»¶ååŒè‡³å…³é‡è¦**: é›†æˆæ–¹æ³•ç»“åˆæœ‰æ•ˆç»„ä»¶ï¼Œè¾¾åˆ°45.0%çš„å‡†ç¡®ç‡ï¼Œä¼˜äº35.0%çš„åŸºçº¿

- **Core Model and Language Matter Most**: Selecting a powerful foundation model (Model_Deepseek-r1) and a strategic language translation approach were the most impactful individual improvements
  - **æ ¸å¿ƒæ¨¡å‹å’Œè¯­è¨€æœ€é‡è¦**: é€‰æ‹©å¼ºå¤§çš„åŸºç¡€æ¨¡å‹ï¼ˆModel_Deepseek-r1ï¼‰å’Œç­–ç•¥æ€§è¯­è¨€ç¿»è¯‘æ–¹æ³•æ˜¯æœ€å…·å½±å“åŠ›çš„å•é¡¹æ”¹è¿›

- **RAG Provides Consistent Gains**: The integration of Retrieval-Augmented Generation (RAG) consistently enhanced performance, confirming the value of external knowledge retrieval
  - **RAGæä¾›ä¸€è‡´æ”¶ç›Š**: æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„é›†æˆæŒç»­æå‡æ€§èƒ½ï¼Œè¯å®äº†å¤–éƒ¨çŸ¥è¯†æ£€ç´¢çš„ä»·å€¼

- **Feedback Mechanism**: The initial feedback mechanism did not yield improvements in this iteration
  - **åé¦ˆæœºåˆ¶**: åˆå§‹åé¦ˆæœºåˆ¶åœ¨æ­¤æ¬¡è¿­ä»£ä¸­æœªäº§ç”Ÿæ”¹è¿›

## ICML 2025 SeePhys Challenge | ICML 2025 SeePhysæŒ‘æˆ˜èµ›

### The Challenge | æŒ‘æˆ˜èµ›ä»‹ç»

**ICML 2025 Challenge Track 2: Physics Reasoning with Diagrams and Expressions (SeePhys)**

**ICML 2025æŒ‘æˆ˜èµ›é“2: å¸¦å›¾è¡¨å’Œè¡¨è¾¾å¼çš„ç‰©ç†æ¨ç†ï¼ˆSeePhysï¼‰**

- **Host**: The International Conference on Machine Learning (ICML), a top-tier conference in AI
- **ä¸»åŠæ–¹**: å›½é™…æœºå™¨å­¦ä¹ ä¼šè®®ï¼ˆICMLï¼‰ï¼ŒAIé¢†åŸŸçš„é¡¶çº§ä¼šè®®
- **Task**: Tests a model's ability to solve complex physics problems by integrating textual descriptions with corresponding diagrams
- **ä»»åŠ¡**: æµ‹è¯•æ¨¡å‹é€šè¿‡æ•´åˆæ–‡æœ¬æè¿°å’Œç›¸åº”å›¾è¡¨æ¥è§£å†³å¤æ‚ç‰©ç†é—®é¢˜çš„èƒ½åŠ›
- **Scope**: Features a comprehensive set of 2,000 problems, with topics ranging from middle school classical mechanics to PhD-level modern physics
- **èŒƒå›´**: åŒ…å«2000ä¸ªé—®é¢˜çš„ç»¼åˆé›†åˆï¼Œä¸»é¢˜ä»ä¸­å­¦ç»å…¸åŠ›å­¦åˆ°åšå£«çº§åˆ«çš„ç°ä»£ç‰©ç†

### Our Achievement | æˆ‘ä»¬çš„æˆå°±

- **Ranked 11th out of 130 International Participants**
  - **åœ¨130ä¸ªå›½é™…å‚èµ›å›¢é˜Ÿä¸­æ’åç¬¬11**
  - Placing our team in the **top 8.5%** of all competing teams
  - å°†æˆ‘ä»¬çš„å›¢é˜Ÿç½®äºæ‰€æœ‰å‚èµ›å›¢é˜Ÿçš„**å‰8.5%**

- **Achieved 42.50% Accuracy**
  - **è¾¾åˆ°42.50%çš„å‡†ç¡®ç‡**
  - On the complete and challenging test set of 2000 multimodal problems
  - åœ¨åŒ…å«2000ä¸ªå¤šæ¨¡æ€é—®é¢˜çš„å®Œæ•´ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„æµ‹è¯•é›†ä¸Š

- **Validation**: This outstanding result validates the effectiveness of our approach in advanced scientific reasoning and establishes a strong performance benchmark
  - **éªŒè¯**: è¿™ä¸€å‡ºè‰²ç»“æœéªŒè¯äº†æˆ‘ä»¬åœ¨é«˜çº§ç§‘å­¦æ¨ç†æ–¹é¢æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å»ºç«‹äº†å¼ºå¤§çš„æ€§èƒ½åŸºå‡†

## Conclusion | ç»“è®º

In this work, we developed and systematically evaluated an agent-based framework for solving complex, illustrated physics problems. Our analysis, conducted on a 200-problem development set, reveals several key insights:

åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼€å‘å¹¶ç³»ç»Ÿè¯„ä¼°äº†ä¸€ä¸ªåŸºäºæ™ºèƒ½ä½“çš„æ¡†æ¶ï¼Œç”¨äºè§£å†³å¤æ‚çš„å›¾ç¤ºç‰©ç†é—®é¢˜ã€‚æˆ‘ä»¬åœ¨200ä¸ªé—®é¢˜çš„å¼€å‘é›†ä¸Šè¿›è¡Œçš„åˆ†ææ­ç¤ºäº†å‡ ä¸ªå…³é”®è§è§£ï¼š

1. **Component Synergy is Crucial**: An integrated method combining effective components achieved 45.0% accuracy, demonstrating the superiority of a holistic approach over single enhancements.
   - **ç»„ä»¶ååŒè‡³å…³é‡è¦**: ç»“åˆæœ‰æ•ˆç»„ä»¶çš„é›†æˆæ–¹æ³•è¾¾åˆ°45.0%çš„å‡†ç¡®ç‡ï¼Œè¯æ˜äº†æ•´ä½“æ–¹æ³•ä¼˜äºå•ä¸€å¢å¼ºã€‚

2. **Core Model and Language Matter Most**: Selecting a powerful foundation model and a strategic language translation approach were the most impactful individual improvements.
   - **æ ¸å¿ƒæ¨¡å‹å’Œè¯­è¨€æœ€é‡è¦**: é€‰æ‹©å¼ºå¤§çš„åŸºç¡€æ¨¡å‹å’Œç­–ç•¥æ€§è¯­è¨€ç¿»è¯‘æ–¹æ³•æ˜¯æœ€å…·å½±å“åŠ›çš„å•é¡¹æ”¹è¿›ã€‚

3. **RAG Provides Consistent Gains**: The integration of Retrieval-Augmented Generation consistently enhanced performance, confirming the value of external knowledge retrieval.
   - **RAGæä¾›ä¸€è‡´æ”¶ç›Š**: æ£€ç´¢å¢å¼ºç”Ÿæˆçš„é›†æˆæŒç»­æå‡æ€§èƒ½ï¼Œè¯å®äº†å¤–éƒ¨çŸ¥è¯†æ£€ç´¢çš„ä»·å€¼ã€‚

The strategic integration of these successful components allowed us to build a highly effective system. This result validates our agent-based methodology as a powerful and promising direction for tackling sophisticated multimodal scientific reasoning tasks.

è¿™äº›æˆåŠŸç»„ä»¶çš„ç­–ç•¥æ€§é›†æˆä½¿æˆ‘ä»¬èƒ½å¤Ÿæ„å»ºä¸€ä¸ªé«˜æ•ˆçš„ç³»ç»Ÿã€‚è¿™ä¸€ç»“æœéªŒè¯äº†æˆ‘ä»¬çš„åŸºäºæ™ºèƒ½ä½“çš„æ–¹æ³•è®ºæ˜¯è§£å†³å¤æ‚å¤šæ¨¡æ€ç§‘å­¦æ¨ç†ä»»åŠ¡çš„æœ‰åŠ›ä¸”æœ‰å‰æ™¯çš„æ–¹å‘ã€‚

## Images | å›¾ç‰‡è¯´æ˜

All images used in this README are stored in the `images/` directory. To add new images:

æœ¬READMEä¸­ä½¿ç”¨çš„æ‰€æœ‰å›¾ç‰‡éƒ½å­˜å‚¨åœ¨ `images/` ç›®å½•ä¸­ã€‚æ·»åŠ æ–°å›¾ç‰‡çš„æ–¹æ³•ï¼š

1. **Place your image file** in the `images/` folder
   - **å°†å›¾ç‰‡æ–‡ä»¶**æ”¾å…¥ `images/` æ–‡ä»¶å¤¹

2. **Use Markdown syntax** in README.md:
   - **åœ¨README.mdä¸­ä½¿ç”¨Markdownè¯­æ³•**:
   ```markdown
   ![Image Description](images/filename.png)
   ```

3. **For size control**, use HTML:
   - **æ§åˆ¶å¤§å°**ï¼Œä½¿ç”¨HTML:
   ```html
   <img src="images/filename.png" alt="Image Description" width="500">
   ```

4. **For GitHub**, use relative paths (images/filename.png) or raw GitHub URLs
   - **å¯¹äºGitHub**ï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ˆimages/filename.pngï¼‰æˆ–GitHub rawé“¾æ¥

### Workflow Diagrams | å·¥ä½œæµå›¾è¡¨

For detailed workflow diagrams of all experimental configurations, see:

æ‰€æœ‰å®éªŒé…ç½®çš„è¯¦ç»†å·¥ä½œæµå›¾è¡¨ï¼Œè¯·å‚è§ï¼š

- **[images/workflows.md](images/workflows.md)** - Complete workflow documentation with diagrams
- **[images/workflows.md](images/workflows.md)** - åŒ…å«å›¾è¡¨çš„å®Œæ•´å·¥ä½œæµæ–‡æ¡£

**Available Workflows | å¯ç”¨å·¥ä½œæµ**:
- Baseline Workflow | åŸºçº¿å·¥ä½œæµ (35.0% accuracy)
- Model Configurations | æ¨¡å‹é…ç½®
- Language Translation | è¯­è¨€ç¿»è¯‘
- RAG Configurations | RAGé…ç½®
- Feedback Loop | åé¦ˆå¾ªç¯
- Integrated Method | é›†æˆæ–¹æ³• (45.0% accuracy)

## Project Structure | é¡¹ç›®ç»“æ„

This repository is organized as follows:

æœ¬ä»“åº“ç»„ç»‡ç»“æ„å¦‚ä¸‹ï¼š

```
â”œâ”€â”€ README.md                    # Main documentation (this file)
â”œâ”€â”€ PROJECT_STRUCTURE.md         # Project structure recommendations
â”œâ”€â”€ images/                      # Images and diagrams
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ workflow/               # Workflow documentation
â”‚   â”œâ”€â”€ dataset/                # Dataset documentation
â”‚   â””â”€â”€ feishu_docs/            # Feishu documents (converted)
â”œâ”€â”€ workflows/                  # Coze workflow resources
â”‚   â”œâ”€â”€ coze_export/           # Exported workflow configs
â”‚   â””â”€â”€ screenshots/           # Workflow screenshots
â”œâ”€â”€ resources/                  # External resources
â”‚   â”œâ”€â”€ links.md               # External links (Coze, Feishu, etc.)
â”‚   â””â”€â”€ references/           # References
â”œâ”€â”€ scripts/                    # Utility scripts
â”œâ”€â”€ examples/                   # Usage examples
â””â”€â”€ ...
```

### Quick Links | å¿«é€Ÿé“¾æ¥

- **ğŸ“š Documentation**: [docs/](docs/)
  - Workflow: [docs/workflow/](docs/workflow/)
  - Dataset: [docs/dataset/](docs/dataset/)
  
- **ğŸ”§ Workflows**: [workflows/](workflows/)
  - Coze workflow: [workflows/README.md](workflows/README.md)
  
- **ğŸ”— Resources**: [resources/](resources/)
  - External links: [resources/links.md](resources/links.md)
  
- **ğŸ“– Examples**: [examples/](examples/)

## Accessing Coze Resources | è®¿é—®Cozeèµ„æº

The project uses Coze platform for workflow implementation and data storage:

æœ¬é¡¹ç›®ä½¿ç”¨Cozeå¹³å°è¿›è¡Œå·¥ä½œæµå®ç°å’Œæ•°æ®å­˜å‚¨ï¼š

- **Coze Workflow**: See [resources/links.md](resources/links.md) for access links
  - **Cozeå·¥ä½œæµ**: å‚è§ [resources/links.md](resources/links.md) è·å–è®¿é—®é“¾æ¥
- **Knowledge Bases**: Physics textbook content and solved problems database
  - **çŸ¥è¯†åº“**: ç‰©ç†è¯¾æœ¬å†…å®¹å’Œå·²è§£å†³é—®é¢˜æ•°æ®åº“
- **Workflow Documentation**: Detailed documentation in [workflows/](workflows/) and [docs/workflow/](docs/workflow/)
  - **å·¥ä½œæµæ–‡æ¡£**: è¯¦ç»†æ–‡æ¡£åœ¨ [workflows/](workflows/) å’Œ [docs/workflow/](docs/workflow/)

## Future Work | æœªæ¥å·¥ä½œ

- [x] Project structure setup
- [x] é¡¹ç›®ç»“æ„è®¾ç½®
- [x] Documentation framework
- [x] æ–‡æ¡£æ¡†æ¶
- [ ] Add Coze workflow screenshots
- [ ] æ·»åŠ Cozeå·¥ä½œæµæˆªå›¾
- [ ] Migrate Feishu documents
- [ ] è¿ç§»é£ä¹¦æ–‡æ¡£
- [ ] Add usage examples
- [ ] æ·»åŠ ä½¿ç”¨ç¤ºä¾‹
- [ ] Further improvements on the 95 consistently incorrect problems
- [ ] å¯¹95ä¸ªæŒç»­é”™è¯¯é—®é¢˜çš„è¿›ä¸€æ­¥æ”¹è¿›

## Local Development | æœ¬åœ°å¼€å‘

This project can be developed locally in Cursor. For local workflow guide, see:

æœ¬é¡¹ç›®å¯ä»¥åœ¨Cursorä¸­æœ¬åœ°å¼€å‘ã€‚æœ¬åœ°å·¥ä½œæµæŒ‡å—ï¼Œè¯·å‚è§ï¼š

- **[LOCAL_WORKFLOW.md](LOCAL_WORKFLOW.md)** - Complete guide for local development and GitHub push
- **[LOCAL_WORKFLOW.md](LOCAL_WORKFLOW.md)** - æœ¬åœ°å¼€å‘å’ŒGitHubæ¨é€å®Œæ•´æŒ‡å—

**Quick Start | å¿«é€Ÿå¼€å§‹**:
1. Edit and complete content locally in Cursor
   - åœ¨Cursorä¸­æœ¬åœ°ç¼–è¾‘å’Œå®Œå–„å†…å®¹
2. When ready, push to GitHub (we can help with Git operations)
   - å‡†å¤‡å¥½åï¼Œæ¨é€åˆ°GitHubï¼ˆæˆ‘ä»¬å¯ä»¥å¸®åŠ©å¤„ç†Gitæ“ä½œï¼‰

---

**Note**: For detailed project structure recommendations, see [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md).

**æ³¨æ„**: è¯¦ç»†çš„é¡¹ç›®ç»“æ„å»ºè®®ï¼Œè¯·å‚è§ [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md)ã€‚

